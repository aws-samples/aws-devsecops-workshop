[
{
	"uri": "/",
	"title": "DevSecOps on AWS",
	"tags": [],
	"description": "",
	"content": "In this workshop we will build a pipeline for a sample WordPress site in a stack. We will explore how to validate, lint and test templates, and dive deeper in tools that help you enforce compliance and network analysis, together with your development pipeline, for a full DevSecOps CI/CD.\n"
},
{
	"uri": "/introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Transitioning to DevOps requires a change in culture and mindset. At its simplest, DevOps is about removing the barriers between traditionally siloed teams; development, operations and security. In some organizations, there may not even be separate development, operations and security teams; engineers may do both. With DevOps, the two disciplines work together to optimize both the productivity of developers and the reliability of operations.\nThe alignment of development and operations teams has made it possible to build customized software and business functions quicker than before, but security teams continue to be left out of the DevOps conversation. In a lot of organizations, security is still viewed as or operates as roadblocks to rapid development or operational implementations, slowing down production code pushes. As a result, security processes are ignored or missed as the DevOps teams view them as a road block toward their pending success. As part of your organization strategy towards a security, automated and orchestrated cloud deployment and operations and you will need to unite the DevOps and SecOps teams in an effort to fully support and operationalize your organizations cloud operations\nSkills Security specialist\n Face a rapidly changing technology landscape Prepared to dive deeper in AWS and take the Security Certification Specialty and learning path How would codified security look like in an envirnoment you own? Start with Python. Lambda, config, other SDKs  Everyone\n Get in the mindset!  Outcome Security teams tend to be an order of magnitude smaller than developer teams. The goal of DevSecOps is to go from security being the \u0026ldquo;department of no\u0026rdquo; to security being an enabler.\nBy the end of this workshop, we want you to have some ideas on how you can accelerate your security teams to keep up with the development team. We want you to be able to react and detect vulnerabilities faster, using event driven architectures.\n  Security and Compliance is a shared responsibility between AWS and the customer. This differentiation of responsibility is commonly referred to as Security “of” the Cloud versus Security “in” the Cloud.   "
},
{
	"uri": "/clone.html",
	"title": "Clone Repository",
	"tags": [],
	"description": "",
	"content": " Clone this repository. From your terminal application, execute the following command. This creates a directory named aws-devsecops-workshop in your current directory.  git clone https://github.com/aws-samples/devsecops-workshop-on-aws cd devsecops-workshop-on-aws Create AWS CodeCommit repository in your AWS account and set up the AWS CLI. Name your repository wordpress-cfn. Alternatively, from your terminal application, execute the following command and note the cloneUrlHttp URL in the response from the CLI.  aws codecommit create-repository --repository-name wordpress-cfn --repository-description \u0026quot;This template installs WordPress with a local MySQL database for storage\u0026quot; pip install git-remote-codecommit Create the local git setup required to push code to CodeCommit repository and add a new remote. From your terminal application, within the \u0026lsquo;devsecops-workshop-on-aws\u0026rsquo; directory, execute the following command:  git init \u0026amp;\u0026amp; git remote add AWSCodeCommit codecommit::eu-west-1://wordpress-cfn Install git-secrets and ensure the git repository is scanned for secrets on each commit.  git clone https://github.com/awslabs/git-secrets.git cd git-secrets \u0026amp;\u0026amp; make install \u0026amp;\u0026amp; cd .. git secrets --install git secrets --register-aws Push the repository into AWS Code Commit.  git push AWSCodeCommit master  git-secrets scans commits, commit messages, and \u0026ndash;no-ff merges to prevent adding secrets into your git repositories. If a commit, commit message, or any commit in a \u0026ndash;no-ff merge history matches one of your configured prohibited regular expression patterns, then the commit is rejected.\n "
},
{
	"uri": "/secrets.html",
	"title": "Store Secrets",
	"tags": [],
	"description": "",
	"content": "When using AWS CloudFormation templates to code your infrastructure, you should consider applying best practices to improve the maintainability of your code. Further, these best practices should be augmented by guidelines like those outlined for twelve-factor apps, which are targeted at optimizing applications for continuous deployment. Of these factors, you should note that you should strive for strict separation of configuration information from your code wherever possible, since configuration information will often vary across deployments, while code typically does not. Also, from a code and configuration perspective, you should strive to keep your development and production code as similar as possible because this will aid quick replication of any production issues or bugs.\nWith AWS CloudFormation, you have several options to avoid storing configuration as constants in your template code, which amounts in most cases to hardcoding runtime configuration details. Instead, you should take advantage of various options for using parameters. Further, you can elicit those parameters from users in the AWS Management Console, or from a separate runtime variable by using a CLI or API call, or by using a parameter file.\n# # This snippet of the template accesses stored parameters # for the database name and passwords. # A non-secure SSM Parameter for the DB name # A Secrets Manager Parameter for the master password # Parameters: DBName: Description: The WordPress database name Default: \u0026#34;{{resolve:ssm:dbName:1}}\u0026#34; Type: String DBPassword: Description: The WordPress database admin account password Default: \u0026#34;{{resolve:secretsmanager:dbPassword}}\u0026#34; Type: String In the console, initialise the parameters the Wordpress stack fetches from AWS Systems Manager Parameter Store and AWS Secrets Manager using your CLI.\naws ssm put-parameter --name dbName --type String --value \u0026#34;WordPressDB\u0026#34; aws ssm put-parameter --name dbUser --type String --value \u0026#34;DBuser\u0026#34; aws secretsmanager create-secret --name dbPassword --secret-string DBPassword aws secretsmanager create-secret --name dbRootPassword --secret-string DBRootPassword AWS Secrets Manager is a service to manage the lifecycle for the secrets used in your organization centrally including rotation, audit, and access control. Secrets Manager helps you meet your security and compliance requirements by enabling you to rotate secrets automatically. Secrets Manager offers built-in integration for MySQL, PostgreSQL, and Amazon Aurora on Amazon RDS that\u0026rsquo;s extensible to other types of secrets by customizing Lambda functions.\nAWS Systems Manager Parameter Store provides secure, hierarchical storage for configuration data management, which can include secrets. Data such as database strings, passwords, and license codes can be stored as parameter values. Values stored can be either plain text or encrypted data. You can then reference values by using the unique name specified when creating the parameter. You can reference Systems Manager parameters in your scripts and commands for configuration and automation workflows.\nGenerally speaking, if you only need simple store/retrieve functionality use AWS Systems Manager Parameter Store. If you wants extra functionality, such as lifecycle management and rotation, use AWS Secrets Manager.\n "
},
{
	"uri": "/launch.html",
	"title": "Launch Stacks",
	"tags": [],
	"description": "",
	"content": "Launch the CloudFormation template that creates the Pipeline in your account.\n\nLets dive into the template file located in ./pipeline/basic-pipeline.yaml. This CloudFormation templates builds a pipeline for a sample WordPress site in a stack. The pipeline is separated into four stages. Each stage must contain at least one action, which is a task the pipeline performs on your artifacts (your input). A stage organizes actions in a pipeline. CodePipeline must complete all actions in a stage before the stage processes new artifacts, for example, if you submitted new input to rerun the pipeline.\nThe pipeline that performs the following workflow:\n  The first stage of the pipeline retrieves a source artifact (an AWS CloudFormation template) from a repository. You\u0026rsquo;ll prepare an artifact that includes a sample WordPress template and upload it to an S3 bucket.\n  In the second stage, the pipeline performs a series of validation tests to the AWS CloudFormation template. These include cfn-validate-template, cfn_nag and taskcat, and then the pipeline continues to the next stage.\n  In the third stage, the pipeline creates a test stack and then waits for your approval. After you review the test stack, you can choose to continue with the original pipeline or create and submit another artifact to make changes. If you approve, this stage deletes the test stack, and then the pipeline continues to the next stage.\n  In the fourth stage, the pipeline creates a change set against a production stack, and then waits for your approval. In your initial run, you won\u0026rsquo;t have a production stack. The change set shows you all of the resources that AWS CloudFormation will create. If you approve, this stage executes the change set and builds your production stack.\n  Open DevSecOps-Wordpress on the CodePipeline console. It looks something like this:\nWhy did the stack failed to run? Click on the details button of the Package Export action, and link to the execution details to look at the build logs.\nOne of the validation tests failed. The output logs the following message:\nAn error occurred (ValidationError) when calling the ValidateTemplate operation: [/Parameters/InstanceType/Default] 'null' values are not allowed in templates We are now deploying the template in ./wordpress/wordpress-single-instance.yaml. Can you find the error on the template?\n"
},
{
	"uri": "/validate.html",
	"title": "Validating a Template",
	"tags": [],
	"description": "",
	"content": "The InstanceType parameter was missing on line 27 of the template. You need to defult it to a specific instance time. In the code sample below, we set the default to a t3.small instance.\nParameters: InstanceType: Default: t3.small Description: WebServer EC2 instance type Type: String To check your template file for syntax errors, we used the aws cloudformation validate-template --template-body file://./wordpress/wordpress-single-instance.yaml command.\nThe aws cloudformation validate-template command is designed to check only the syntax of your template. It does not ensure that the property values that you have specified for a resource are valid for that resource. Nor does it determine the number of resources that will exist when the stack is created.\n During validation, AWS CloudFormation first checks if the template is valid JSON. If it isn\u0026rsquo;t, AWS CloudFormation checks if the template is valid YAML. If both checks fail, AWS CloudFormation returns a template validation error. You can validate templates locally by using the --template-body parameter, or remotely with the --template-url parameter.\nTo check the operational validity, you need to attempt to create the stack. There is no sandbox or test area for AWS CloudFormation stacks, so you are charged for the resources you create during testing.\nIf commit and push our changes, and go back to the CodePipeline console, the execution is stil failing. Let\u0026rsquo;s do that and have a look again at the build logs.\ngit add wordpress/wordpress-single-instance.yaml git commit -m \u0026#34;Added a default instance type of t3.small\u0026#34; git push AWSCodeCommit master This time we got something different:\n------------------------------------------------------------ wordpress/wordpress-single-instance.yaml ------------------------------------------------------------------------------------------------------------------------ | WARN W27 | | Resources: [\u0026quot;WebServerSecurityGroup\u0026quot;] | Line Numbers: [142] | | Security Groups found ingress with port range instead of just a single port Failures count: 0 Warnings count: 1 "
},
{
	"uri": "/cfn-nag.html",
	"title": "Linting a Template",
	"tags": [],
	"description": "",
	"content": "Our Security group defined on the wordpress/wordpress-single-instance.yaml file on line 141 is too permissive because we have a range of ports open. Let’s narrow the range to only the one port we need for Wordpress to work. In the code sample below, you will note the Security Group resource restricts to only port 80.\nWebServerSecurityGroup: Type: AWS::EC2::SecurityGroup Properties: GroupDescription: \u0026#34;Enable HTTP access via port 80 locked down to the load balancer + SSH access\u0026#34; VpcId: \u0026#34;default-vpc\u0026#34; SecurityGroupIngress: - CidrIp: 0.0.0.0/0 FromPort: 80 IpProtocol: tcp ToPort: 80 Commit the changes and push it to CodeCommit:\ngit add wordpress/wordpress-single-instance.yaml git commit -m \u0026#34;Closed down SG to port 80\u0026#34; git push AWSCodeCommit master The cfn-nag tool parses a collection of CloudFormation templates and applies rules to find code patterns that could lead to insecure infrastructure. The results of the tool include the logical resource identifiers for violating resources and an explanation of what rule has been violated.\nWhile there are quite a number of particular rules the tool will attempt to match, the rough categories are:\n IAM and resource policies (S3 Bucket, SQS, etc.)  Matches policies that are overly permissive in some way (e.g. wildcards in actions or principals)   Security Group ingress and egress rules  Matches rules that are overly liberal (e.g. an ingress rule open to 0.0.0.0/0, port range 1-65535 is open)   Access Logs  Looks for access logs that are not enabled for applicable resources (e.g. Elastic Load Balancers and CloudFront Distributions)   Encryption  (Server-side) encryption that is not enabled or enforced for applicable resources (e.g. EBS volumes or for PutObject calls on an S3 bucket)    All the rules are considered either warnings or failures. Any discovered failures will result in a non-zero exit code, while warnings will not. In the context of a delivery pipeline, cfn-nag should likely stop the pipeline in the case it finds failures, but perhaps not stop the pipeline in the case of just warnings. Which rules are considered warnings and which are considered errors is a little “loose” or subjective.\nThe cfn-nag tool includes rules that apply universally across environments and enterprises (you can still filter which ones you want to suppress). That said, the product supports the development of custom rules to allow enterprise-specific rules for compliance and security controls.\n However, the execution is still failing. There is one thing left to solve. Can you guess what the problem is?\n2020-04-20 13:21:59.423000+00:00 CREATE_FAILED AWS::EC2::SecurityGroup WebServerSecurityGroup The vpc ID 'default-vpc' does not exist (Service: AmazonEC2; Status Code: 400; Error Code: InvalidVpcID.NotFound; Request ID: eb225981-a162-4555-bf51-4cfe66056c20) "
},
{
	"uri": "/taskcat.html",
	"title": "Testing a Template",
	"tags": [],
	"description": "",
	"content": "The vpc ID default-vpc on wordpress/wordpress-single-instance.yaml line 145 does not exist. If we ommit the security group on a CloudFormation template it will default to the default VPC, so let\u0026rsquo;s do exactly that. Delete line 145 all together to get the following security group:\nWebServerSecurityGroup: Type: AWS::EC2::SecurityGroup Properties: GroupDescription: \u0026#34;Enable HTTP access via port 80 locked down to the load balancer + SSH access\u0026#34; SecurityGroupIngress: - CidrIp: 0.0.0.0/0 FromPort: 80 IpProtocol: tcp ToPort: 80 And commit and push the changes:\ngit add wordpress/wordpress-single-instance.yaml git commit -m \u0026#34;Removed default-vpc on the SG\u0026#34; git push AWSCodeCommit master TaskCat is a tool that tests AWS CloudFormation templates. It deploys your AWS CloudFormation template in multiple AWS Regions and generates a report with a pass/fail grade for each region. You can specify the regions and number of Availability Zones you want to include in the test, and pass in parameter values from your AWS CloudFormation template. taskcat is implemented as a Python class that you import, instantiate, and run.\nTaskcat uses two configuration files: Global config and Project config. The global config file provides global settings that become defaults for all projects. It is located in user’s home-directory ~/.taskcat.yml. The project config file provides project-specific configurations. The project config file is located in the root of your project folder \u0026lt;PROJECT_ROOT\u0026gt;/.taskcat.yml\nproject: name: wordpress-single-instance regions: - eu-west-1 tests: default: template: wordpress/wordpress-single-instance.yaml TaskCat performs multiple actions, such as template validation, parameter validation, and staging content into an Amazon Simple Storage Service (Amazon S3) bucket, before launching the AWS CloudFormation stack. It launches the stack in the defined Regions, simultaneously. And it regularly polls the AWS CloudFormation stack status to check if the stack creation is finished. After the stack has been successfully created, TaskCat deletes it. How much time TaskCat takes to finish the testing depends on how many tests you have defined in your TaskCat configuration file and how long each stack creation and deletion takes. After the TaskCat run is completed, it generates a report in HTML format in the directory from where you are running the TaskCat command.\nParameter Overrides were added to the taskcat to solve a couple of common problems. First, many templates share common parameters that are unique to an AWS account, like a KeyPair name or an S3 Bucket, overrides provided a way to store those centrally for all your projects. Second, we didn’t want to add sensitive data (usernames, passwords, tokens) to a git repository. The idea was to store sensitive/unique data outside of a git repository, but still execute a test using this data. To that end, any parameter defined in the global config will take precedence over the same parameter in a project-level config.\n The stack is now waiting for manual approval and an email on your inbox asking for it. However, we received another email from AWS Config. It says:\nA Config rule is not compliant in your environment. Please open the Config Dashboard for further details. "
},
{
	"uri": "/config/soak.html",
	"title": "Soak Testing Environment",
	"tags": [],
	"description": "",
	"content": "We confugred AWS Config rules in our test environment, which represent our ideal configuration settings. The current rule we are using, vpc-default-security-group-closed, checks that the default security group of any VPC does not allow inbound or outbound traffic. If we navigate to the AWS Config console we can see our non-compliant rule:\nOur default security group is too permissive. Let\u0026rsquo;s close it down. Fisrt, click on the security group ID to go to the VPC Management Console. The default security groups looks something like this:\nClick on \u0026ldquo;Edit inbound rules\u0026rdquo; and delete the rule. After this, do the same for the Outbound rules. Going back to the Config console, click on \u0026ldquo;Re-evaluate\u0026rdquo; and watch the rule become compliant!\nWe are now ready to approve our commit to production.\n"
},
{
	"uri": "/config.html",
	"title": "Enforcing Compliance",
	"tags": [],
	"description": "",
	"content": "The flexible, dynamic nature of the AWS cloud gives developers and admins the flexibility to launch, configure, use, and terminate processing, storage, networking, and other resources as needed. In any fast-paced agile environment, security guidelines and policies can be overlooked in the race to get a new product to market before the competition.\nImagine that you had the ability to verify that existing and newly launched AWS resources conformed to your organization’s security guidelines and best practices without creating a bureaucracy or spending your time manually inspecting cloud resources.\nAWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations. With Config, you can review changes in configurations and relationships between AWS resources, dive into detailed resource configuration histories, and determine your overall compliance against the configurations specified in your internal guidelines. This enables you to simplify compliance auditing, security analysis, change management, and operational troubleshooting.\n AWS Config is designed to help you assess compliance with your internal policies and regulatory standards by providing you visibility into the configuration of your AWS resources as well as third-party resources, and evaluating resource configuration changes against your desired configurations on a continuous basis.\nYou can use AWS Config as your framework for creating and deploying governance and compliance rules across your AWS accounts and regions. You can codify your compliance requirements as AWS Config rules and author remediation actions using AWS Systems Manager Automation documents and package them together within a conformance pack that can be easily deployed across an organization. Therefore, using AWS Config, you can automate assessment of your resource configurations and resource changes to help you ensure continuous compliance and self-governance across your AWS infrastructure.\n"
},
{
	"uri": "/config/works.html",
	"title": "How AWS Config Works",
	"tags": [],
	"description": "",
	"content": "When you turn on AWS Config, it first discovers the supported AWS resources that exist in your account and generates a configuration item for each resource.\nAWS Config also generates configuration items when the configuration of a resource changes, and it maintains historical records of the configuration items of your resources from the time you start the configuration recorder. By default, AWS Config creates configuration items for every supported resource in the region. If you don\u0026rsquo;t want AWS Config to create configuration items for all supported resources, you can specify the resource types that you want it to track.\nAWS Config keeps track of all changes to your resources by invoking the Describe or the List API call for each resource in your account. The service uses those same API calls to capture configuration details for all related resources.\nFor example, removing an egress rule from a VPC security group causes AWS Config to invoke a Describe API call on the security group. AWS Config then invokes a Describe API call on all of the instances associated with the security group. The updated configurations of the security group (the resource) and of each instance (the related resources) are recorded as configuration items and delivered in a configuration stream to an Amazon Simple Storage Service (Amazon S3) bucket.\nAWS Config also tracks the configuration changes that were not initiated by the API. AWS Config examines the resource configurations periodically and generates configuration items for the configurations that have changed.\nIf you are using AWS Config rules, AWS Config continuously evaluates your AWS resource configurations for desired settings. Depending on the rule, AWS Config will evaluate your resources either in response to configuration changes or periodically. Each rule is associated with an AWS Lambda function, which contains the evaluation logic for the rule. When AWS Config evaluates your resources, it invokes the rule\u0026rsquo;s AWS Lambda function. The function returns the compliance status of the evaluated resources. If a resource violates the conditions of a rule, AWS Config flags the resource and the rule as noncompliant. When the compliance status of a resource changes, AWS Config sends a notification to your Amazon SNS topic.\n"
},
{
	"uri": "/config/rules.html",
	"title": "Evaluating Resources with Rules",
	"tags": [],
	"description": "",
	"content": "Use AWS Config to evaluate the configuration settings of your AWS resources. You do this by creating AWS Config rules, which represent your ideal configuration settings. AWS Config provides customizable, predefined rules called managed rules to help you get started. You can also create your own custom rules. While AWS Config continuously tracks the configuration changes that occur among your resources, it checks whether these changes violate any of the conditions in your rules. If a resource violates a rule, AWS Config flags the resource and the rule as noncompliant.\nFor example, when an EC2 volume is created, AWS Config can evaluate the volume against a rule that requires volumes to be encrypted. If the volume is not encrypted, AWS Config flags the volume and the rule as noncompliant. AWS Config can also check all of your resources for account-wide requirements. For example, AWS Config can check whether the number of EC2 volumes in an account stays within a desired total, or whether an account uses AWS CloudTrail for logging.\nThe AWS Config console shows the compliance status of your rules and resources. You can see how your AWS resources comply overall with your desired configurations, and learn which specific resources are noncompliant. You can also use the AWS CLI, the AWS Config API, and AWS SDKs to make requests to the AWS Config service for compliance information.\nBy using AWS Config to evaluate your resource configurations, you can assess how well your resource configurations comply with internal practices, industry guidelines, and regulations.\nAWS Config Managed Rules AWS Config provides AWS managed rules, which are predefined, customizable rules that AWS Config uses to evaluate whether your AWS resources comply with common best practices. For example, you could use a managed rule to quickly start assessing whether your Amazon Elastic Block Store (Amazon EBS) volumes are encrypted or whether specific tags are applied to your resources. You can set up and activate these rules without writing the code to create an AWS Lambda function, which is required if you want to create custom rules. The AWS Config console guides you through the process of configuring and activating a managed rule. You can also use the AWS Command Line Interface or AWS Config API to pass the JSON code that defines your configuration of a managed rule.\nYou can customize the behavior of a managed rule to suit your needs. For example, you can define the rule\u0026rsquo;s scope to constrain which resources trigger an evaluation for the rule, such as EC2 instances or volumes. You can customize the rule\u0026rsquo;s parameters to define attributes that your resources must have to comply with the rule. For example, you can customize a parameter to specify that your security group should block incoming traffic to a specific port number.\nAfter you activate a rule, AWS Config compares your resources to the conditions of the rule. After this initial evaluation, AWS Config continues to run evaluations each time one is triggered. The evaluation triggers are defined as part of the rule, and they can include the following types:\nConfiguration changes – AWS Config triggers the evaluation when any resource that matches the rule\u0026rsquo;s scope changes in configuration. The evaluation runs after AWS Config sends a configuration item change notification.\nPeriodic – AWS Config runs evaluations for the rule at a frequency that you choose (for example, every 24 hours).\nRemediating Resources and Rules AWS Config allows you to remediate noncompliant resources that are evaluated by AWS Config Rules. AWS Config applies remediation using AWS Systems Manager Automation documents. These documents define the actions to be performed on noncompliant AWS resources evaluated by AWS Config Rules. You can associate SSM documents by using AWS Management Console or by using APIs.\nAWS Config provides a set of managed automation documents with remediation actions. You can also create and associate custom automation documents with AWS Config rules.\nTo apply remediation on noncompliant resources, you can either choose the remediation action you want to associate from a prepopulated list or create your own custom remediation actions using SSM documents. AWS Config provides a recommended list of remediation action in the AWS Management Console.\nIn the AWS Management Console, you can either choose to manually or automatically remediate noncompliant resources by associating remediation actions with AWS Config rules. With all remediation actions, you can either choose manual or automatic remediation.\n"
},
{
	"uri": "/conclusion.html",
	"title": "Conclusion and Clean Up",
	"tags": [],
	"description": "",
	"content": "It\u0026rsquo;s done! We managed to deploy our Wordpress stack making sure we have security in our development pipeline. To get started building your DevSecOps approach, take a step back and ask yourself, “What am I trying to accomplish, and what security controls are needed?”. This step helps you create a focused use case, and from there, you can identify options for security tools, automation requirements, and organizational roles and processes that you need to address. Finally, include an audit, logging, and monitoring solution in your production environment that combines account activity and AWS resources from AWS CloudTrail and AWS CloudWatch with data on security incidents to provide ongoing insights, as well as other controls, such as Identity and Access Management (IAM) and network security.\nTo cleanup the resources, destroy the CloudFormation template in your account and the CodeCommit repository:\naws cloudformation delete-stack --stack-name devsecops-wordpress-pipeline aws codecommit delete-repository --repository-name wordpress-cfn "
},
{
	"uri": "/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]